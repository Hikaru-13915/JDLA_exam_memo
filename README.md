
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>
# JDLA_exam_memo
E資格対策のための殴り書きメモ

# 前書き
E資格の[シラバス](https://www.jdla.org/download/e-syllabus_2022/)に準拠して個人的に作成した試験対策まとめです。  
個人的に、最低限これを覚えていたらいいかなと思ったキーワードを各章であげています。
※間違っているとこあったらおしえてください。

# 1-応用数学
## 1.1-確率統計
確率関数とは、$X=x$となる確率をxの関数として表現した関数。  
### 1.1.1-一般的な確率分布
ベルヌーイ分布と多項分布(マルチヌーイ)とガウス分布への理解度を問う内容。  
- ベルヌーイ分布  
確率$p$で、$x=0$を、確率$1-p$で、$x=1$をとる確率関数$f(x)$は以下の式で表現できる。  
$$ f(x) = p^x(1-p)^{1-x} $$  
この確率分布関数$f(x)$に従う確率の期待値は、  
$$ E(x) = \sum_{x=0}^1{f(x)} = \sum_{x=0}^1{xp^x(1-p)^{1-x}} = p$$
であり、分散は、  
$$ V(x) = E(x^2)-{E(x)}^2=\sum_{x=0}^1{x^2p^x(1-p)^{1-x}}-p^2 = p(1-p)$$
と表現できる。  
$\hat {p}=\frac{1}{n}\sum_{i=0}^n{x_i}$のときに尤度関数が最大となる。  
- マルチヌーイ分布  
ワンホットベクトル(1成分のみが1で残りのすべての成分が0であるベクトル)で表現された確率  


- ガウス分布(正規分布)  
以下の関数で表現できる。  
$$ f(x ; \mu ) = \frac {1} {\sqrt{2\pi\sigma^2}}exp{\frac {(x-\mu)^2}{2\sigma^2}}$$  
分散が$\sigma^2=1$であれば、$\mu=\frac{1}{n}\sum_{i=0}^n{x_i}$のときに尤度関数が最大となる。

### 1.1.2-ベイズ則
この章では条件付確率に関する定義式のみ覚えていれば問題なさそう。  
ベイズ則とは、ベイズの定理を指し、以下の内容である。  
B が起こったもとで 、A が起こるという「条件付き確率」は、
$$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$$
で表せる。
ただし、$P(B|A)P(A)=P(A \cap B)$または、 $P(B|A)P(A)=P(A,B)$とも表すことが可能。  
※補足 Pが連続分布であれば$P(B)=\int P(A,B) dA$と表現可能。


## 1.2-情報理論
### 1.2.1-情報理論

自己情報量 : $I(x)=-logP(x)$  
エントロピー : $H[P(x)] = - \int P(x)logP(x)dx $  →情報価値  
交差エントロピー : $H[p,q] = - \sum qlogp $  →二つの確率分布の近さ  
KLダイバージェンス : $ KL[q(x)][p(x)] = \sum_xp(x)log_2\frac{p(x)}{q(x)}$  →二つの確率分布の近さ

# 2-機械学習
## 2.1-機械学習の基礎

- Mitchell(1997)の機械学習定義
```txt
コンピュータプログラムは、性能指標Pで測定されるタスクTにおける性能が経験Eにより改善される場合、
そのタスクTのクラス及び性能指標Pに関して経験Eが学習する。
```

### 2.1.1-学習アルゴリズム
#### 教師あり学習
- SVM (one-class SVMは教師なし)  
サポートベクトル以外のtrain-dataが境界面に影響しないため、外れ値に対してもロバストである。
カーネルトリックに用いることのできる関数。
非線形な境界面に使えるものは、ガウスと多項式とラプラスカーネル等。

- ロジスティック回帰  
シグモイドを恒等写像関数として用いる。  
分類問題のための線形モデル。
出力がモデルの信頼度。多クラス分類の際は出力関数をソフトマックス関数を利用する。


### 2.1.2-機械学習学習課題
過少適合：機械学習をしていく上で学習が不足して適切な学習ができていないこと  
過剰適合：機械学習をしていく上で学習をしすぎて適切な学習ができていない  
過学習：訓練データに適合しすぎてテストデータでは良い精度が出せない  

- ノーフリーランチ定理
```txt
コスト関数の極値を探索するあらゆるアルゴリズムは、
全ての可能なコスト関数に適用した結果を平均すると同じ性能となる。
```
タダで食べられるランチがあるなんて、そんないい話があるわけないだろう、というのが名前の由来だそう。  
詰まるところが、究極に優れたアルゴリズムがあるっていうのは何か裏がある。(そのタスクのみでしか精度を発揮しない等。)

- 次元の呪い  
```txt
次元の数が増えると、高い精度のモデルを作るために必要なデータ量が指数関数的に増えちゃう。
```
### 2.1.3-ハイパーパラメータ
### 2.1.4-検証集合
交差検証、ホールドアウトが説明できればいい。  
### 2.1.5-最尤推定
最尤推定において、未知のデータ生成分布$P_{data(x)}$から生成された集合$X$と、パラメトリックな集合$P_{model}(x; θ)$があったとき、θの推定量は$θ_{ML} = argmax P_{model}(X; θ)$である。  
またこのときのデータの分布誤差を、KLダイバージェンスで$logP_{model}(x)$と表すことが可能。  

最尤推定量：尤度関数が最大となるように定義づけられる確率分布が、データに最もよく当てはまるような、パラメータの推定量。
### 2.2-実用的な方法論
アンサンブル：複数のモデルを組み合わせて新たなモデルを作ること
アンサンブルにはバギング、ブースティング、スタッキングの三種類がある。  
- バギング(ブートストラップ・アグリゲーティングとも呼ばれている)
並列的に弱学習器を用いて各モデルの総合的な結果を用いる手法。
バギングでは、バリアンスをおさえることが可能。
- ブースティング  
ブースティングでは直列的に弱学習器をつないで学習する。  
最初の弱学習器で推定できなかった部分を推定するため、重みを付けて次の弱学習器で学習を行う。  
バイアスを低くすることが可能。  
- スタッキング  
新たな特徴量を作る方法。SVMのような感覚。  

### 2.2.1-性能指標
recall(適合率), precisionとか覚えとく。IoU。
$recall = \frac {TP}{TP+FN}$
$IoU=\frac{正解領域\cap予測領域}{正解領域\cup予測領域}$  

### 2.2.2-ハイパーパラメータの選択
グリッドサーチ、ランダムサーチが説明できればいい。
### 2.3-強化学習
### 2.3.1-方策勾配法
方策勾配定理  
$$\nabla_\theta J(\theta) = E_{\pi_\theta}[\nabla_\theta log{\pi_\theta(a|s)Q^{\pi_\theta}(s,a)}]$$  
Q学習はsarsaより行動価値関数の収束が遅い。

### 2.3.2-価値反復法(DQN)
$$L(\theta)=E[(r+\gamma \max_{a'}Q(s',a';\theta)-Q(s,a;\theta))^2]$$

以下の3ステップで構成されている。  

- Experienced Replay  
経験を$e_t=\{s_t,a_t,r_t,s_{t+1}\}$として保存し、損失計算に用いる。  
- Target Q-network  
上式の$E$を$E_{s,a,r,s'\sim D}$とし  
上式の二乗項の一項目の$\theta$を$\theta^-$に変更。
- 報酬のクリッピング  
値を{-1,0,1}に固定。→勝率がわかる。  
これによりゲームごとに楽手率を変える必要がなくなる。  


発展形がA3C  
- AlphaStar  
video game版alphaGoみたいなやつ    
# 3-深層学習
はじめてDeep Learningの手法を取り入れたモデル：AlexNet(2012)  
活性化関数は全てReluである。maxプーリングを採用。
## 3.1-順伝播型ネットワーク
### 3.1.1-全結合型ニューラルネットワーク
スカラー積のオペレーションに関して
$$y=x_1 \cdot x_2$$
を満たすとき、
目的関数$L$についての各要素の逆伝播を表す式は以下の通り、
$$\frac{\partial L}{\partial x_1}=\frac{\partial L}{\partial y} \times x_2$$
$$\frac{\partial L}{\partial x_2}=\frac{\partial L}{\partial y} \times x_1$$
### 3.1.2-損失関数
学習における交差エントロピーは以下の式で表現される。  
$$\sum(y_{true} log(y_{pred} + error))$$
### 3.1.3-活性化関数
- relu関数  
$max(0, x)$で表せる。数式では以下の通り、  
$$ f(x)=
\left\{
\begin{array}{ll}
x & (x \geq 0)\\
0 & (x < 0)
\end{array}
\right.

$$

- softmax   
$$f(x)=\frac {e^{x_i}}{\sum_i x_i}$$ 
で表せる。  

- LeakyRelu
$$ f(x)=
\left\{
\begin{array}{ll}
x & (x \geq 0)\\
0.01x & (x < 0)
\end{array}
\right.

$$
- シグモイド関数  
$$\sigma(x)=\frac{1}{1+e^{-x}}$$
- 線形ユニットの特徴  
出力ユニットに線形ユニットを用いることで飽和を防ぎ、勾配に基づいた最適化手法をが利用可能。  

- tanh関数  
$$\tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}$$

### 3.1.4-誤差伝播法とその他微分アルゴリズム

一般的に入力xに処理f(x)を行ってyが得られたとする。($y=f(x)$)  
yからf(x)に向かう逆伝播誤差をEとすると  
xへの逆伝播誤差$\delta(x)$は以下のように表現できる。
$$\delta(x)=E\frac {dy}{dx}$$

## 3.2-深層モデルのための正則化
### 3.2.1-パラメータノルムペナルティ
- lasso：l1 normによる最適化  
L1正則化は次元削減に使われ、外れデータの影響を0にする手法である。  

- ridge(l2の実装)  
L2正則化はデータを滑らかにする手法である。二乗項のノルム。
```python
# X^2に対して、係数付きの単位行列を加え、その逆行列と「X,yの内積」との内積を求める。
temp = X.T.dot(X) + alpha * np.eye(X.shape[1])
ridge = np.linalg.inv(temp).dot(X.T.dot(y))
```


- 正則化のときの注意点。  
ニューラルネットワークにて正則化を用いる際、各層ごとに異なる正則化係数を設定しても良い。  
正則化係数が大きいと過少適合になる恐れあり。  
L1,L2の融合版がエラスティックネット(sklearnに関数あり)  

### 3.2.2-データ集合の拡張
### 3.2.3-ノイズに対する頑丈性
### 3.2.4-マルチタスク学習
### 3.2.5-早期終了
### 3.2.6-スパース表現
値の多くを0にし、計算を高速化させること
### 3.2.7-バギングとアンサンブル手法
### 3.2.8-ドロップアウト
要らん中間層不活性にするやつ。  
drop_ratio$r$を超える出力にはマスク係数$m$との積として出力し、  
$r$以下のものには$(1-r)$との積を出力する。
## 3.3-深層モデルのための最適化
### 3.3.1-学習と純粋な最適化の差異
ニューラルネットワークの重みが大きすぎると、勾配爆発が起こる。
### 3.3.2-基本的な学習アルゴリズム
確率的勾配降下法とモメンタムを覚えること。  

### 3.3.3-パラメータの初期化戦略
### 3.3.4-適応的な学習率を持つアルゴリズム
AdaGradとRMSropとAdamを覚えること。

### 3.3.5-最適化戦略とアルゴリズム
- バッチ正規化  
チャンネルごとに行う正規化。訓練時の移動平均をテストに用いる。重みの初期化が不要で、学習率を大きくできる。  
```python
each_batch = offset_learn_rate_factor * (data_t[i][j] - batch_mean) / np.sqrt(dispersion + 1e-8)\
     + scale_learn_rate_factor
```  

- レイヤー正規化  
バッチ中のテータごとに行う。層内の全ユニットが対象なのでミニバッチ内では各データごとに用いることが可能。平均と分散($\mu,\sigma$)がそれぞれ異なる。  
- インスタンス正規化  
チャンネルとバッチごとに行う。コンテントimageとstyle-imageを合成するタスク等に用いる。H×Wの軸に対して$\mu,\sigma$を計算。  
- グループ正規化  
バッチ中のデータごとに行う。  

- ニュートン法  
二次でない表面についてはヘッセ行列が正定値である限り、ニュートン法を反復的に適用可能。  
一般的に近似的関数の表面は、鞍点のような多くの特徴を持つ非凸面であり、それがニュートン法による更新の妨げとなる。(鞍点が苦手)  
勾配方向$d$を求め、$f(x - αd)$を最小化する$α$を求めることで解を近似可能。  

## 3.4-畳み込みネットワーク
### 3.4.1-畳み込み処理
畳み込みの基本的な計算式は以下の通り、
$$(I*K)(i*j)=\sum_m{\sum_n I(i+m,j+n)K(m,n)}$$  
画像サイズW×W, フィルタサイズH×H, パディングP, ストライドSの畳み込みをした場合、畳み込み後の画像のサイズは
$$(\frac{W - H + 2P}{S} + 1)^2$$  

- point-wise畳み込み  
1×1サイズのフィルタ。チャンネルサイズを合わせるために使う。  
- depth-wise  
チャンネルごとに畳み込み  
- grouped畳み込み  
複数チャンネルを1グループとみなし畳み込む。チャンネル方向のパラメータを削減。    
- dilated畳み込み    
畳み込みのフィルタ間隔を広げる。  

### 3.4.2-プーリング
特定の範囲ごとにmax, meanを計算するため、入力データの微小変化に呈してほぼ不変。  
学習によって定めるパラメータはない。
## 3.5-回帰結合型ニューラルネットワークと再帰的ネットワーク
### 3.5.1-回帰結合型ニューラルネットワーク
### 3.5.2-双方向RNN
順方向と逆方向に依存する出力を得たい場合に使用される。  系列の開始から同じ向きに移動するRNNと、系列の終わりから時間とは逆方向に移動するRNNを組み合わせたもの。出力ユニットが過去と未来の両方に依存する表現を計算可能。
### 3.5.3-Encoder-DecoderとSequence-to-Sequebce
- Encoder-Decoder  
Encoderと呼ばれるRNNが入力を処理し、文脈Cを出力する。
Decoderは出力系列Yを生成するために固定長のベクトルによって条件付けられている。
すべてのデータのペアについてlogP(Y)の平均を最大化するよう2つのRNNが同時に学習を進める。
### 3.5.4-長期依存性の課題
RNNは、学習を進めていくと重みWの固有値がt乗されていくため、固有値が1に満たない場合は0に収束し、1より大きい場合は発散してしまう。  

- エコースティックネットワーク  
回帰隠れユニットが過去の入力の履歴をうまく補足できる。
重みをスペクトル半径に固定することによって勾配が爆発対策。  
ESNに重みを設定することによって重みを初期化でき、長期依存性の学習に貢献。
### 3.5.5-ゲート付きRNN
- LSTM  
忘却ゲート、
入力ゲート、
出力ゲート。  
中間層処理
```python
w = = np.random.randn(n_input + n_hidden, n_hidden * 4)
next_h = c * forget_gate + np.tanh(z) * input_gate
```
- GRU  
リセットゲート。リセットゲートの出力と1時刻前のGRUのアダマール積が、外部入力と$tanh$関数に入力される。  
入力ゲート、出力ゲート、忘却ゲートの代わりに更新ゲート。  
更新ゲートと1時刻前のGRUのアダマール席が出力に加算される。  
実装する際はLSTMと同様にmodel.add(GRU())。  


### 3.5.6-長期依存性の最適化
勾配のクリッピング  $if ||g|| > v$であれば、  
$$ g <- \frac{gv}{||g||}
$$
### 3.5.7-Attention
## 3.6-生成モデル
### 3.6.1-識別モデルと生成モデル
識別モデルは入力データのクラスごとの分布確率を知ることができる。  
生成モデルは識別モデルと異なり、入力データの生成過程やクラスごとのデータ分布等を求められる。  
### 3.6.2-オートエンコーダ
VAEでは隠れ変数zの近似を以下の式で行う。  
$z = \mu+\varepsilon\sigma (\varepsilon \sim N(0,I))$  
また損失関数は以下の式で表せられる。  
$$L = -E_{z\sim p(z|x)}[logp(x|z)]+D_{KL}(p(z|x)||p(z))$$

$D_{KL}$：KLダイバージェンス  
デコーダが分散一定の正規分布に従うとき、$-logL \sim \frac {1}{z} ||x-x'||^2$に近似可能。  
- VQ-VAE
VAEを基に新しい埋め込み空間の構造とそれを元にした潜在変数のベクトル量子化処理が追加されたもの  

### 3.6.3-GAN
訓練データから新データを生成するネットワークと、  
与えられたデータが訓練データであるか前記生成データであるかを判別するネットワーク  
の2つを交互に学習する敵対生成モデル。  
学習の収束は$D(x)=0.5$  
目的関数は、
$$\min_G{\max_D Ex[logD(x)]+log(1-D(G(x)))}$$
で表現される。(__超重要__)  
- DC-GAN  
畳み込みありのGAN  
- Conditionl GAN  
条件を生成データに与える。→pix2pixがこれ。  

## 3.7-深層強化学習
- AlphaGo  
モンテカルロ木探索で選択肢を評価。「勝率」と「バイアス」に深層学習モデルを使った補正を行う。打った手の勝率の予測を勝率の補正に使い、次の一手の予測をバイアスの補正に使う。勝敗のカウントは、計算の速いロジスティック回帰が手を進めた結果を数える。  
以下の3ステップがある。  
$z$：報酬  $P(s,a)$：SLによって与えられる事前確率  
1. 学習時、プロの手を見本にSL(supervised learning)を行う。このとき、$$\triangle \sigma = \frac{\alpha}{m} \sum_{k=1}^m \frac {\partial logP_\sigma (a^k|s^k)}{\partial \sigma}$$
を加える。  
2. RL(reiforce learning)を行う。  
$$\triangle \rho = \frac{\alpha}{n} \sum_{i=1}^n \sum_{t=1}^{T^i} \frac {\partial logP_\rho (a_t^i|s_t^i)}{\partial \rho}(z_t^i-v(s_t^i))$$
で更新。  
3. 価値観数 $v(s)$を評価。価値ネットワークを学習。
$$v(s)=E[z_t|s_t=s, a_t \sim p]$$

$\triangle \theta = \frac{\alpha}{m} \sum_{k=1}^m (z^k-{v_\theta}(s^k) \frac {\partial v_\theta (s^k)}{\partial \theta})$  

対戦時は、  
$t < U$ でSL  
$t = U$ でランダム  
$t > U$ でRLから差し手を選択する。  


シミュレーションを繰り返し探索終了後に、訪問回数の多いルートを採用。  
## 3.8-グラフニューラルネットワーク
## 3.9-深層学習の適用方法
### 3.9.1-画像認識
- GoogLeNet(2014)
2014年に開発された、ネットワークを縦方向だけでなく横方向にまで拡張した高速モデル。  
22 layers。 inception module。GAP(Global Average Pooling)でパラメータ削減, AuxliaryLossで勾配消失対策。  
※inception module：大きな畳み込みフィルタを小さな畳み込みフィルタのグループで近似し、モデルの表現力とパラメータ数のトレードオフを改善。1×1の畳み込みフィルタが使われており、次元削減と等価な効果がある。小さなネットワークを一つのモジュールとして定義し、モジュールの積み重ねでネットワークを構築している。  

- ResNet(2015)  
VGGをベースとしてスキップ構造を採用している。max pooling。層間をまたぐ結合ではIdentity mappingにより勾配消失対策。  
層の深さを浅くし、フィルタ数を増やしてネットワークの幅を広くして改良→WideResNet    

- DenseNet(2016)  
全層結合が特徴。勾配消失問題対策。param数が従来より大幅に減った。  

- EfficientNet(2019)  
Googleが開発したモデル。少ないparamで高性能。  

### 3.9.2-画像の局在化・検知・セグメンテーション
- R-CNN
Selective Search  
- FasterR-CNN  
提案領域に対してCNNで特徴マップを生成し、RoI Poolingで固定サイズに変形。Region Proposal Networkと呼ばれるCNNで物体の候補領域を探す。また、end-to-end学習が可能。


FCNの出力：画像サイズ×分類クラス数
### 3.9.3-自然言語処理
- WordEmbedding  
単語やフレーズをベクトルに変換する。  

- Transformer(2017)  
Attention エンコーダデコーダあり、全結合層あり。  
Query, Key, Valueについて  
$Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{dk}})V$  
勾配縮小化予防がなされている。  
RNN,CNNなしに系列データの処理が可能。   

- BERT(2018)  
transformerのエンコーダーを採用。
事前学習にて、単語マスク(局所的な特徴量のため)と、次の分かどうかの予測問題を扱う。(大局的な特徴量のため)  
再学習は教師あり学習で行い、以下の作業を必要とする。　　
1. トークン埋め込み  
単語の違いを表現  
2. セグメント埋め込み  
文の違いを表現  
3. ポジション埋め込み  
単語の順序を意味する情報  

### 3.9.4-音声処理
メル尺度：人間の聴覚は低周波数域では分解能が高く、高周波数域では分解能が低くなる

- CTC  
異なる系列長の音声のデータの入出力での認識を可能にした手法。「ブランク」と呼ばれる何もないことを表す記号がある。ニューラルネットワークのみで音声認識を実現可能。  
- wavenet  
pixel CNNに基づく音声生成モデル。  
causal dilated convolutionを採用。  
causal: 入力データが順番被らないことを保証できる。再帰結合無しで、RNNより高速。画像のマスク畳み込みに似ている。  
dilated: フィルターを適用する入力データの位置を数ステップずつ飛ばして擬似的にフィル長より長い受容野をもつ。  

拡大度は出力に向かうほど大きくなる。  

### 3.9.5-スタイル変換
## 3.10-距離学習
### 3.10.1-2サンプルによる比較
Siamese Network：比較しているサンプルが類似しているときは、ニューラルネットワークが出力した特徴ベクトルの距離を近く、類似していないときは遠ざけるように学習を行う。
### 3.10.2-3サンプルによる比較
Triplet Network：出力される結果がコンテキスト(例 麺類、小麦粉から作られた食べ物)によって影響を受けるという問題を抱えている
## 3.11-メタ学習
学習する方法を学ぶという概念  
- MAML(Model-Agnostic Meta-Learning)  
```txt
少ないデータでの学習が可能で、転移学習との相性が良い。
異なるタスク間での知識の転移を容易にし、一度学習した知識を別の関連するタスクに効果的に適用できる。  
迅速な適応性が特徴。  

二段階の学習プロセスがあり、
1段階目では、多様なタスクのデータセットを使用してモデルのパラメータを更新。
次の段階では、新しいタスクのデータセットでのパフォーマンスを最適化。  
初期パラメータの最適化を行う。

最適な学習経路の探索も可能。  
様々なタスクを効果的に学習するための最適な学習経路を探索。新しいタスクに対しても効果的に対応可能。  
```
## 3.12-深層学習の説明性
### 3.12.1-判断根拠の可視化
Grad-CAM：特徴マップに対する重みの値を推論時の勾配情報を用いた値に変更することでCNN内部の状態を考慮することが可能
### 3.12.2-モデルの近似
SHAP：複雑なモデルの局所的な近似。ゲーム理論関連。

入力 $𝑥=[𝑥1,⋯,𝑥𝑀]^𝑇 と学習したモデル$f$に対し、  
以下のようにモデルgで近似(ただし$z'=[{z'}_1,{z'}_2,.....,{z'}_M]$)

$$
g(z')=\phi_0 + \sum_{i=1}^M{\phi_i {z'}_i}  
$$
# 4-開発と運用環境
## 4.1 ミドルウェア
TensorFlowが対応したdefine-by-runは、計算する時に具体的なモデルを構築する
TensorFlowはGoogle社が開発したフレームワークである。
PyTorchはFacebook社が開発したフレームワークである。
## 4.2 エッジコンピューティング
蒸留：高精度な大規模モデルを用いて小さいモデルの学習を行う方法
### 4.2.1 軽量なモデル
- MobileNet(2017)  
depth-wise separable convolutionという畳み込みを採用。  
### 4.2.2 モデル軽量化
## 4.3 分散処理
同期型は偏ったデータを基に勾配を計算しても、影響を受けにくい。
### 4.3.1 モデル並列
### 4.3.2 データ並列
## 4.4 アクセラレータ  
GPUとかの話です。  
## 4.5 環境構築
dockerとかの話です。  
